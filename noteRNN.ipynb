{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "noteRNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsaxby/NoteRNN/blob/master/noteRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "OhTN_2KPUZsC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tn95SUj9UcaT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7x_RbL87UK-W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.lines as mlines\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "!pip install music21\n",
        "from music21 import *\n",
        "!pip install pygame\n",
        "import pygame\n",
        "from google.colab import files\n",
        "#configure.run()\n",
        "import glob\n",
        "from torch import optim\n",
        "from torchvision import datasets\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5e4p5Fy-UqTU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# directory where we store our music data\n",
        "data_dir = '/content/drive/My Drive/Colab Notebooks/data/music_data/music/hozier/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "flrHnYJRUr92",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Dataset():\n",
        "  def __init__(self, data_dir):\n",
        "    self.chords = {} # dict of chords\n",
        "    self.notes = [] # list of all extracted notes from songs\n",
        "    self.unique_notes = None # set of unique notes\n",
        "    self.data_dir = data_dir # data directory where midi files are stored/saved\n",
        "    self.midi_files = [] # list of all midi files extracted from data_dir\n",
        "    self.pitch2int = self.pitch_to_int() # dict of unique notes & chords\n",
        "    self.num_classes = None # num of unique notes\n",
        "    self.rests = {} # dict of rests\n",
        "    \n",
        "  # takes in a directory, extracts notes from all songs \n",
        "  # returns all notes in a single array\n",
        "  def create_dataset(self):\n",
        "      for file in glob.glob(self.data_dir+\"/*.mid\"):\n",
        "          try:\n",
        "              midi = self.open_midi(file)\n",
        "              self.midi_files.append(midi)\n",
        "              self.extract_notes(midi)\n",
        "              \n",
        "          except:\n",
        "              print(\"Could not process: {}\".format(file))  \n",
        "      self.pitch_to_int()\n",
        "      self.encode_notes()\n",
        "  # extract notes from a midi file\n",
        "  # return notes as string or note object\n",
        "  def extract_notes(self, midi):\n",
        "    notes_to_parse = None\n",
        "    # get a list of all the notes and chords in the file\n",
        "    parts = instrument.partitionByInstrument(midi)\n",
        "    \n",
        "    if parts: # if the file has instrument parts\n",
        "      notes_to_parse = parts.parts[0].recurse()\n",
        "    else: # file has notes in a flat structure\n",
        "      notes_to_parse = midi.flat.notes\n",
        "\n",
        "    for nt in notes_to_parse:\n",
        "                # try Note.isRest\n",
        "      if isinstance(nt, note.Rest):\n",
        "         # encode the rest\n",
        "        encoded_rest = self.encode_rest(str(nt.fullName))\n",
        "        # add to notes\n",
        "        self.notes.append(encoded_rest)\n",
        "         #add encoded rest object to dict for later song generation\n",
        "        self.rests[nt.fullName] = nt\n",
        "     # Note.isNote\n",
        "      if isinstance(nt, note.Note):\n",
        "        # append the pitch of note object using its string notation \n",
        "        self.notes.append(str(nt.pitch))\n",
        "      # Note.isChord\n",
        "      elif isinstance(nt, chord.Chord):           \n",
        "        self.notes.append(str(nt))\n",
        "        self.chords[str(nt)] = nt\n",
        "\n",
        "              \n",
        "  # encode prev 10 note history in rests\n",
        "  def encode_rest(self, rest):\n",
        "    encoded_rest = \"\"\n",
        "    # if the song starts with a rest, don't\n",
        "    # encode the rest\n",
        "    if len(self.notes) == 0:\n",
        "      return rest\n",
        "    # get the previous 10 notes to\n",
        "    # be encoded with this rest\n",
        "    if len(self.notes) >= 10:\n",
        "      rng = -10\n",
        "    elif len(self.notes) < 10: # if the length of notes is less than 10, use all notes\n",
        "      rng = 0\n",
        "    for note in self.notes[rng:]:\n",
        "      encoded_rest += note\n",
        "    return encoded_rest +\"$\"+ rest\n",
        "  \n",
        "  # open midi file\n",
        "  def open_midi(self, file_name):\n",
        "    print(\"Processing {}...\".format(file_name))\n",
        "    return converter.parse(file_name)\n",
        "\n",
        "  # list instruments: Takes in a midi file\n",
        "  # and prints instruments in the file\n",
        "  def list_instruments(self, midi):\n",
        "    # start part stream\n",
        "    partStream = midi.parts.stream()\n",
        "    print(\"Instruments on MIDI file:\")\n",
        "    for part in partStream:\n",
        "        print(part.partName)\n",
        "\n",
        "  # analyze timeSignature and music keys\n",
        "  def analyze_song(self, midi):\n",
        "      # get the time signatures\n",
        "      timeSig = midi.getTimeSignatures()[0]\n",
        "      # get the key\n",
        "      musicAnalysis = midi.analyze('key')\n",
        "      print(\"Time signature: {0}/{1}\".format(timeSig.beatCount, timeSig.denominator))\n",
        "      print(\"Expected music key: {0}\".format(musicAnalysis))\n",
        "      print(\"Music key confidence: {0}\".format(musicAnalysis.correlationCoefficient))\n",
        "\n",
        "  # play midi file\n",
        "  def play_song(self, midi_file):\n",
        "      print(\"Playing MIDI...\")\n",
        "      song = midi.realtime.StreamPlayer(midi_file)\n",
        "      song.play()\n",
        "\n",
        "  # save midi file\n",
        "  def save_song(self, midi, file_name):\n",
        "      midi.write('mid', fp=self.data_dir+file_name)\n",
        "\n",
        "\n",
        "  # takes in a str and creates a music21 note object\n",
        "  def create_note(self, note):\n",
        "      return pitch.Pitch(note).midi\n",
        "    \n",
        "  # encode a note\n",
        "  def pitch_to_int(self):\n",
        "      # get unique pitch names\n",
        "      self.unique_notes=sorted(set(item for item in self.notes))\n",
        "      # map pitches to ints\n",
        "      # note will be the key\n",
        "      self.pitch2int = dict((note, number) for number, note in enumerate(self.unique_notes))\n",
        "      self.num_classes = len(self.pitch2int)\n",
        "  \n",
        "  # encode notes in a song\n",
        "  def encode_notes(self):\n",
        "      encoded_notes = []\n",
        "      # for each note in the song, encode it as an int, and add it to\n",
        "      # the encoded list\n",
        "      for i in range(0, len(self.notes)):\n",
        "          encoded_notes.append(self.pitch2int[self.notes[i]])\n",
        "      self.encoded_notes = np.array(encoded_notes)\n",
        "      \n",
        "  # save extracted notes as CSV for easy upload/access\n",
        "  def save_notes(self):\n",
        "    df = pd.DataFrame(self.notes)\n",
        "    df.to_csv(\"notes.csv\", header=None, index=None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k_iNnCZqUvTM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# helper functions \n",
        "\n",
        "def to_categorical(x, num_classes):\n",
        "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
        "    return np.eye(num_classes, dtype=np.float32)[x]\n",
        "  \n",
        "\n",
        "def get_batches(arr, batch_size, seq_length):  \n",
        "  \n",
        "  '''          \n",
        "  Generator which creates batches of dim (batch_size * seq_length)\n",
        "  batch_size = num sequences in a batch\n",
        "  seq_length = num of notes in a sequence\n",
        "  '''\n",
        "  batch_size_total = batch_size * seq_length\n",
        "  # total number of batches we can make\n",
        "  n_batches = len(arr)//batch_size_total\n",
        "\n",
        "  # keep only enough notes to make full batches\n",
        "  arr = arr[:n_batches * batch_size_total]\n",
        "  # reshape so we have as many rows/sequences as batch_size\n",
        "  arr = arr.reshape((batch_size, -1))\n",
        "\n",
        "  # iterate through the arr (cols), one sequence at a time\n",
        "  for n in range(0, arr.shape[1], seq_length):\n",
        "      # features\n",
        "      x = arr[:, n:n+seq_length]\n",
        "      # targets\n",
        "      y = np.zeros_like(x)\n",
        "      try:\n",
        "          # targets are shifted by one\n",
        "          y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
        "      except IndexError:\n",
        "          # grab last target values \n",
        "          y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
        "      yield x, y\n",
        "\n",
        "# save the model\n",
        "def save_model(best=False):\n",
        "  if best:\n",
        "    model_name = 'best_noteRNN.net'\n",
        "    print(\"Saving Best Perf Model....\")\n",
        "  else:\n",
        "    model_name = 'noteRNN.net'\n",
        "\n",
        "  checkpoint = {'state_dict': net.state_dict(),\n",
        "                'input_size': net.num_classes,\n",
        "                'output_size': net.num_classes,\n",
        "                'criterion_state': criterion.state_dict(),\n",
        "                'optimizer_state': optimizer.state_dict(),\n",
        "                'epochs': num_epochs}\n",
        "  # model.cpu()\n",
        "  try:\n",
        "    torch.save(checkpoint, model_name)\n",
        "  except:\n",
        "    print(\"Unable to save..\")\n",
        "\n",
        "model_name = 'noteRNN.net'\n",
        "#save_model()\n",
        "#files.download(model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zI_rt8K7Uv7E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NoteRNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, unique_notes, num_hidden=256, num_layers=3,\n",
        "                               dropout=0.5, lr=0.003):\n",
        "        super().__init__()\n",
        "        self.dropout = dropout\n",
        "        self.num_layers = num_layers\n",
        "        self.num_hidden = num_hidden\n",
        "        self.lr = lr\n",
        "        self.num_classes = len(unique_notes)\n",
        "            \n",
        "        # note dictionaries\n",
        "        self.note2int = dict((note, number) for number, note in enumerate(unique_notes))\n",
        "        self.int2note = dict(enumerate(self.note2int))\n",
        "        \n",
        "        # define LSTM\n",
        "        self.lstm = nn.LSTM(self.num_classes, num_hidden, num_layers, \n",
        "                            dropout=dropout, batch_first=True)\n",
        "        \n",
        "        # define dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        # define (fully connected) output layer\n",
        "        self.fc = nn.Linear(num_hidden, self.num_classes)\n",
        "      \n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        ''' Forward pass through the network. \n",
        "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
        "                \n",
        "        # get outputs and new hidden state from LSTM\n",
        "        r_output, hidden = self.lstm(x, hidden)\n",
        "        \n",
        "        # dropout layer\n",
        "        out = self.dropout(r_output)\n",
        "        \n",
        "        # Stack up LSTM outputs using view\n",
        "        # for multiple, use contiguous to reshape the output\n",
        "        out = out.contiguous().view(-1, self.num_hidden)\n",
        "        \n",
        "        # fully-connected layer\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        # return final output and hidden state\n",
        "        return out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # create 2 tensors of dim: (n_layers x batch_size x n_hidden)\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.num_layers, batch_size, self.num_hidden).zero_().cuda(),\n",
        "                  weight.new(self.num_layers, batch_size, self.num_hidden).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.num_layers, batch_size, self.num_hidden).zero_(),\n",
        "                      weight.new(self.num_layers, batch_size, self.num_hidden).zero_())\n",
        "        \n",
        "        return hidden\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yXjBRxCQUxpd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(net, data, epochs=100, batch_size=10, seq_length=60, lr=0.001, clip=5, val_split=0.1, print_every=20):\n",
        "    '''          \n",
        "        net: a NoteRNN network\n",
        "        data: encoded notes from which to train the network\n",
        "        epochs: num of epochs to train\n",
        "        batch_size: batch size\n",
        "        seq_length: num of notes per batch\n",
        "        lr: learning rate\n",
        "        clip: gradient clipping\n",
        "        val_split: amount of data to reserve for validation split\n",
        "        print_every: num of steps for printing training and validation loss\n",
        "    \n",
        "    '''\n",
        "        \n",
        "\n",
        "    net.train()\n",
        "\n",
        "\n",
        "    # create training and val set\n",
        "    split = int(len(data)*(1-val_split))\n",
        "    data, val_data = data[:split], data[split:]\n",
        "    if(train_on_gpu):\n",
        "        net.cuda()\n",
        "    \n",
        "    counter = 0\n",
        "    num_notes = net.num_classes\n",
        "    val_loss_min = np.Inf # track change in validation loss\n",
        "    for epoch in range(epochs):\n",
        "        # initialize hidden state\n",
        "        h = net.init_hidden(batch_size)\n",
        "        \n",
        "        for x, y in get_batches(data, batch_size, seq_length):\n",
        "            counter += 1\n",
        "            \n",
        "            # One-hot encode\n",
        "            x = to_categorical(x, num_notes)\n",
        "            # make torch tensors\n",
        "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
        "            # switch to gpu\n",
        "            if(train_on_gpu):\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "            # Creating new variables for the hidden state, otherwise\n",
        "            # we'd backprop through the entire training history\n",
        "            h = tuple([each.data for each in h])\n",
        "\n",
        "            # zero out gradient\n",
        "            net.zero_grad()\n",
        "            \n",
        "            # get output from net\n",
        "            output, h = net(inputs, h)\n",
        "            \n",
        "            # calculate the loss\n",
        "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
        "            # backprop\n",
        "            loss.backward()\n",
        "            \n",
        "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "            \n",
        "            # update weights and biases\n",
        "            optimizer.step()\n",
        "                        \n",
        "            # loss stats\n",
        "            if counter % print_every == 0:\n",
        "                print(\"Calculating loss...\")\n",
        "                # Get validation loss\n",
        "                val_h = net.init_hidden(batch_size)\n",
        "                val_losses = []\n",
        "                # turn dropout off\n",
        "                net.eval()\n",
        "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
        "                    # One-hot encode \n",
        "                    x = to_categorical(x, num_notes)\n",
        "                    # make Torch tensors\n",
        "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
        "                    \n",
        "                    # Creating new variables for the hidden state, otherwise\n",
        "                    # we'd backprop through the entire training history\n",
        "                    val_h = tuple([each.data for each in val_h])\n",
        "                    \n",
        "                    inputs, targets = x, y\n",
        "                    # move targets/inputs to gpu\n",
        "                    if(train_on_gpu):\n",
        "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "                    # get output from net \n",
        "                    output, val_h = net(inputs, val_h)\n",
        "                    # calc loss\n",
        "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
        "                    val_losses.append(val_loss.item())\n",
        "                # turn dropout back on for training\n",
        "                net.train()\n",
        "                \n",
        "                print(\"Epoch: {}/{}...\".format(epoch+1, epochs),\n",
        "                      \"Step: {}...\".format(counter),\n",
        "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
        "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
        "                \n",
        "                # save model if validation loss has decreased\n",
        "                if val_loss.item() <= val_loss_min:\n",
        "                    print('Saving best performing model...')\n",
        "                    save_model(best=True)\n",
        "                    val_loss_min = val_loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ESAaYZmnQHOa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create dataset\n",
        "hozier = Dataset(data_dir)\n",
        "hozier.create_dataset()\n",
        "chords_ = hozier.chords # retrieve chords for song generation\n",
        "rests_ = hozier.rests # retrieve rests for song generation\n",
        "print(\"Vocab size: {}\".format(hozier.num_classes))\n",
        "encoded_notes = hozier.encoded_notes # encode notes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GQ04O1YoU2EQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define and print the network\n",
        "num_hidden=512\n",
        "num_layers=3\n",
        "\n",
        "net = NoteRNN(hozier.unique_notes, num_hidden, num_layers)\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YtB04JbhU3U_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "batch_size = 10 # increase with larger dataset\n",
        "seq_length = 10 # seq length really matters- it's the amount of context the net receives!\n",
        "num_epochs = 5\n",
        "# optimizer and criterion\n",
        "optimizer = torch.optim.RMSprop(net.parameters(), lr=0.01) #RMSprop good for RNNs\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8jEFCYeuU6Zp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "train(net, encoded_notes, epochs=num_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.01, print_every=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ahm0lFmiU8Nc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# predict takes in a trained network and returns\n",
        "# hidden state and the predicted next note\n",
        "def predict(net, note, h=None, top_k=None):\n",
        "        # tensor inputs\n",
        "        # encode note\n",
        "        x = np.array([[net.note2int[note]]])\n",
        "        # one hot encode\n",
        "        x = to_categorical(x, net.num_classes)\n",
        "        inputs = torch.from_numpy(x)\n",
        "        \n",
        "        if(train_on_gpu):\n",
        "            inputs = inputs.cuda()\n",
        "        \n",
        "        # detach hidden state from history\n",
        "        h = tuple([each.data for each in h])\n",
        "        \n",
        "        # get the output of the model\n",
        "        out, h = net(inputs, h)\n",
        "\n",
        "        # get the character probabilities\n",
        "        p = F.softmax(out, dim=1).data\n",
        "        if(train_on_gpu):\n",
        "            p = p.cpu() # move to cpu\n",
        "        \n",
        "        # get top predicted notes\n",
        "        if top_k is None:\n",
        "            top_ch = np.arange(net.num_classes)\n",
        "        else:\n",
        "            p, top_ch = p.topk(top_k)\n",
        "            top_ch = top_ch.numpy().squeeze()\n",
        "        \n",
        "        # select the likely next note with some element of randomness\n",
        "        p = p.numpy().squeeze()\n",
        "        note = np.random.choice(top_ch, p=p/p.sum())\n",
        "        \n",
        "        # return the encoded value of the predicted note and the hidden state\n",
        "        return net.int2note[note], h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SvJFsb_8U_Hx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# generate a sample of notes given a list of notes (prime)\n",
        "def sample(net, size, prime=['C'], top_k=None):\n",
        "        \n",
        "    if(train_on_gpu):\n",
        "        net.cuda()\n",
        "    else:\n",
        "        net.cpu()\n",
        "    # eval mode (don't want dropout on)\n",
        "    net.eval() \n",
        "    \n",
        "    # retrieve all notes from prime\n",
        "    notes = [nt for nt in prime]\n",
        "    h = net.init_hidden(1)\n",
        "    for nt in notes:\n",
        "        \n",
        "        # predict next note for each note\n",
        "        nt, h = predict(net, nt, h, top_k=top_k)\n",
        "        # check if note is in the dictionary\n",
        "        while nt not in net.note2int:\n",
        "          nt, h = predict(net, nt, h, top_k=top_k)\n",
        "\n",
        "    notes.append(nt)\n",
        "    \n",
        "    # use the output (last predicted note) to generate new prediction\n",
        "    for ii in range(size):\n",
        "        nt, h = predict(net, notes[-1], h, top_k=top_k)\n",
        "        notes.append(nt)\n",
        "\n",
        "    return notes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hPruM-3kbxLR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Song:\n",
        "  def __init__(self, chords, notes, rests, data_dir, file_name):\n",
        "    self.chords = chords\n",
        "    self.notes = notes\n",
        "    self.rests = rests\n",
        "    self.data_dir = data_dir\n",
        "    self.file_name = file_name\n",
        "    \n",
        "  def create_rest(self, nt):\n",
        "    # rests are seen as note objects without a pitch attached\n",
        "    # duration should be set to the rest, velocity = 0, pitch = none  \n",
        "    rest_list = []\n",
        "    # rests\n",
        "    r = nt.split('$') # split on the separator\n",
        "    for elem in r: # sometimes more than one rest is included\n",
        "      if \"Rest\" in elem:\n",
        "        rest_ = elem\n",
        "        if not elem.endswith(\"Rest\"):\n",
        "          rest_ = str(elem.split(\"Rest\")[0]) + \"Rest\"\n",
        "\n",
        "        new_rest = note.Rest()\n",
        "        new_rest.duration= self.rests[rest_].duration\n",
        "        rest_list.append(new_rest)\n",
        "        velocity = 0\n",
        "        duration = rest_list[0]\n",
        "    return velocity, duration\n",
        "\n",
        "  def create_chord(self, nt):\n",
        "    #chords\n",
        "    c = self.chords[nt]\n",
        "    c.volume = volume.Volume(velocity=90)\n",
        "    c.volume.velocityIsRelative = False\n",
        "    eventList = midi.translate.chordToMidiEvents(c)\n",
        "    return eventList\n",
        "\n",
        "\n",
        "        \n",
        "    # create a midi file using the generated notes\n",
        "  def create_song(self):\n",
        "    '''\n",
        "    notes: array of generated notes \n",
        "    chords: a chord dict from the dataset\n",
        "    data_dir: directory (where to save the file), and \n",
        "    file name: desired file name\n",
        "\n",
        "    '''\n",
        "    file_path = self.data_dir+self.file_name\n",
        "    # [duration, pitch, velocity]\n",
        "    data = []\n",
        "    mt = midi.MidiTrack(1)\n",
        "    t=0\n",
        "    tLast=0\n",
        "    for nt in self.notes:                  \n",
        "        if \"Chord\" in nt and \"Rest\" not in nt:  \n",
        "          # get chord\n",
        "          eventList = self.create_chord(nt)\n",
        "          #add to track events\n",
        "          for event in eventList:\n",
        "              mt.events.append(event)\n",
        "\n",
        "        else:\n",
        "          if \"Rest\" in nt: \n",
        "            # create rests\n",
        "            velocity, duration = self.create_rest(nt)\n",
        "            pitch_ = None\n",
        "          # takes in a str and creates a music21 note object\n",
        "          else:\n",
        "            duration = 1024 \n",
        "            velocity = 70 # The attribute stores an integer representation (0-127)\n",
        "            pitch_ = pitch.Pitch(nt).midi\n",
        "\n",
        "            data.append([duration, pitch_, velocity])\n",
        "\n",
        "            for d,p,v in data:\n",
        "                # delta time is how long to wait from the last event\n",
        "                dt = midi.DeltaTime(mt)\n",
        "                dt.time = t-tLast\n",
        "                #add to track events\n",
        "                mt.events.append(dt)\n",
        "                # create event\n",
        "                me=midi.MidiEvent(mt)\n",
        "                # add notes\n",
        "                me.type=\"NOTE_ON\"\n",
        "                me.channel=1 # specify channel\n",
        "                me.time= None \n",
        "\n",
        "                # if not a rest\n",
        "                if p:\n",
        "                  me.pitch = p # note\n",
        "                me.velocity = v \n",
        "                # add the event to the track\n",
        "                mt.events.append(me)\n",
        "                # create delta time\n",
        "                dt = midi.DeltaTime(mt)\n",
        "                dt.time = d\n",
        "                # add time change event to the track\n",
        "                mt.events.append(dt)\n",
        "                # create event\n",
        "                me=midi.MidiEvent(mt)\n",
        "                # add note off\n",
        "                me.type=\"NOTE_OFF\"\n",
        "                me.channel=1 # specify channel\n",
        "                me.time= None \n",
        "                me.pitch = p # note\n",
        "                me.velocity = 0 # equivalent to NOTE_OFF\n",
        "                mt.events.append(me)\n",
        "                tLast = t+d \n",
        "                # increase t for a longer rest\n",
        "                t +=d+1\n",
        "    # create delta time\n",
        "    dt=midi.DeltaTime(mt)\n",
        "    dt.time = 0 # end of track, dt=0\n",
        "    mt.events.append(dt)\n",
        "    # create end of track event\n",
        "    me = midi.MidiEvent(mt)\n",
        "    me.type = \"END_OF_TRACK\"\n",
        "    me.channel = 1 # specify channel\n",
        "    me.data =''  # must set data to empty string\n",
        "    mt.events.append(me)\n",
        "\n",
        "    mf = midi.MidiFile()\n",
        "    mf.ticksPerQuarterNote = 1024 # experiment with different timing\n",
        "    mf.tracks.append(mt)\n",
        "\n",
        "    # write midi file\n",
        "    print(\"Writing MIDI track\")\n",
        "    mf.open(file_path, 'wb')\n",
        "    mf.write()\n",
        "    mf.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lDVueencU_u-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# generate notes\n",
        "generated_notes = sample(net, 20, prime=['<music21.chord.Chord D4 B3 G1 G3 B3 G3 D4>'], top_k = 5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KrIwvlpBVBLT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create song and save it\n",
        "song = Song(chords_,generated_notes, rests_, data_dir, \"generated_hozier_1.mid\")\n",
        "song.create_song()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AUzy4aDGb-HK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "enDNHNLyU1lN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c7ErKOx0z-M-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sNnLnZSj03_h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u2IWPXrB3GFM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uUEnHNvl3S3W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CyTxuJVF3Zzj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}