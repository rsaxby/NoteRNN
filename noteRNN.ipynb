{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "noteRNN_v2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsaxby/NoteRNN/blob/master/noteRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "CJuXsQxPVqkM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN for Music Generation"
      ]
    },
    {
      "metadata": {
        "id": "ZLuU2NCG98JG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import PyTorch"
      ]
    },
    {
      "metadata": {
        "id": "OhTN_2KPUZsC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GBKGLr6g-GRc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive to get data\n"
      ]
    },
    {
      "metadata": {
        "id": "tn95SUj9UcaT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IzDCiNex-X3t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import libraries and check if we can train on GPU"
      ]
    },
    {
      "metadata": {
        "id": "7x_RbL87UK-W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.lines as mlines\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "!pip install music21\n",
        "from music21 import *\n",
        "!pip install pygame\n",
        "import pygame\n",
        "from google.colab import files\n",
        "#configure.run()\n",
        "import glob\n",
        "from torch import optim\n",
        "from torchvision import datasets\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pxuB1qJFBckH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prepare the Dataset\n",
        "The `Dataset` class creates a dataset from MIDI files in the directory specified by `data_dir`. Here we extract and sequentially store note, chord, and rest objects from the MIDI file stream in a list (to be fed to the network for training). Each object is also stored in a dictionary music21_objects, which we will later use to create MIDI events from using our generated notes.\n",
        "Within the `create_dataset` method, we:\n",
        "\n",
        "\n",
        "1.   Extract and store all note/chord/rest objects\n",
        "2.   Create a dictionary to encode our unique objects\n",
        "3.   Encode our list of notes to be used for training"
      ]
    },
    {
      "metadata": {
        "id": "flrHnYJRUr92",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Dataset():\n",
        "  def __init__(self, data_dir):\n",
        "    self.notes = [] # list of all extracted notes from songs (string form)\n",
        "    self.music21_objects = {} # list of all note objects from songs\n",
        "    self.unique_notes = None # set of unique notes\n",
        "    self.data_dir = data_dir # data directory where midi files are stored/saved\n",
        "    self.pitch2int = self.pitch_to_int() # dict of unique notes & chords\n",
        "    self.num_classes = None # num of unique notes\n",
        "    \n",
        "  # takes in a directory, extracts notes from all songs \n",
        "  # returns all notes in a single array\n",
        "  def create_dataset(self):\n",
        "    num_files = len([name for name in glob.glob(data_dir+\"/*.MID\")])\n",
        "    count = 1\n",
        "    for file in glob.glob(self.data_dir+\"/*.MID\"):\n",
        "      print(\"\\n{}/{} Processing {}...\\n\".format(count, num_files, file.strip(self.data_dir),))\n",
        "      try:\n",
        "          midi = self.open_midi(file)\n",
        "          self.extract_notes(midi)\n",
        "          \n",
        "      except:\n",
        "          print(\"Could not process: {}\".format(file))\n",
        "      count += 1 \n",
        "    self.pitch_to_int()\n",
        "    self.encode_notes()\n",
        "     \n",
        "  # extract notes from a midi file\n",
        "  # return notes as string or note object\n",
        "  def extract_notes(self, midi):\n",
        "    notes_to_parse = None\n",
        "    \n",
        "    # get a list of all the notes and chords in the file\n",
        "    parts = instrument.partitionByInstrument(midi)\n",
        "    \n",
        "    if parts: # if the file has instrument parts\n",
        "      notes_to_parse = list(parts.parts[0].recurse())\n",
        "    else: # file has notes in a flat structure\n",
        "      notes_to_parse = midi.flat.notes\n",
        "    \n",
        "    for el in notes_to_parse: \n",
        "      if isinstance(el, note.Rest):\n",
        "        # encode the rest\n",
        "        encoded_rest = self.encode_rest(el.fullName)\n",
        "        self.notes.append(encoded_rest)\n",
        "        # add music21 object to note dictionary\n",
        "        self.music21_objects[el.fullName] = el\n",
        "\n",
        "      elif isinstance(el, note.Note):\n",
        "        # append the note using its full name (str) to the list of notes\n",
        "        self.notes.append(el.fullName)\n",
        "        # append the note object to a list of notes for encoded_rests          \n",
        "        self.music21_objects[el.fullName] = el\n",
        "\n",
        "      elif isinstance(el, chord.Chord):\n",
        "          self.notes.append(el.commonName)\n",
        "          self.music21_objects[el.commonName] = el \n",
        "        \n",
        "  # encode prev 10 note history in rests\n",
        "  def encode_rest(self, rest):\n",
        "    encoded_rest = \"\"\n",
        "    # if the song starts with a rest, don't\n",
        "    # encode the rest\n",
        "    if len(self.notes) == 0:\n",
        "      return rest\n",
        "    # get the previous 10 notes to\n",
        "    # be encoded with this rest\n",
        "    if len(self.notes) >= 10:\n",
        "      rng = -10\n",
        "    elif len(self.notes) < 10: # if the length of notes is less than 10, use all notes\n",
        "      rng = 0\n",
        "    for nt in self.notes[rng:]:\n",
        "      encoded_rest += nt\n",
        "    return encoded_rest +\" $\"+ rest\n",
        "  \n",
        "  # open midi file\n",
        "  def open_midi(self, file_name):\n",
        "    return converter.parse(file_name)\n",
        "\n",
        "  # list instruments: Takes in a midi file\n",
        "  # and prints instruments in the file\n",
        "  def list_instruments(self, midi):\n",
        "    # start part stream\n",
        "    partStream = midi.parts.stream()\n",
        "    print(\"Instruments on MIDI file:\")\n",
        "    for part in partStream:\n",
        "        print(part.partName)\n",
        "\n",
        "  # analyze timeSignature and music keys\n",
        "  def analyze_song(self, midi):\n",
        "      # get the time signatures\n",
        "      timeSig = midi.getTimeSignatures()[0]\n",
        "      # get the key\n",
        "      musicAnalysis = midi.analyze('key')\n",
        "      print(\"Time signature: {0}/{1}\".format(timeSig.beatCount, timeSig.denominator))\n",
        "      print(\"Expected music key: {0}\".format(musicAnalysis))\n",
        "      print(\"Music key confidence: {0}\".format(musicAnalysis.correlationCoefficient))\n",
        "\n",
        "  # play midi file\n",
        "  def play_song(self, midi_file):\n",
        "      print(\"Playing MIDI...\")\n",
        "      song = midi.realtime.StreamPlayer(midi_file)\n",
        "      song.play()\n",
        "\n",
        "  # save midi file\n",
        "  def save_song(self, midi, file_name):\n",
        "      midi.write('mid', fp=self.data_dir+file_name)\n",
        "\n",
        "\n",
        "  # takes in a str and creates a music21 note object\n",
        "  def create_note(self, note):\n",
        "      return pitch.Pitch(note).midi\n",
        "    \n",
        "  # encode a note\n",
        "  def pitch_to_int(self):\n",
        "      # get unique pitch names\n",
        "      self.unique_notes=sorted(set(item for item in self.notes))\n",
        "      # map pitches to ints\n",
        "      # note will be the key\n",
        "      self.pitch2int = dict((note, number) for number, note in enumerate(self.unique_notes))\n",
        "      self.num_classes = len(self.pitch2int)\n",
        "  \n",
        "  # encode notes in a song\n",
        "  def encode_notes(self):\n",
        "      encoded_notes = []\n",
        "      # for each note in the song, encode it as an int, and add it to\n",
        "      # the encoded list\n",
        "      for i in range(0, len(self.notes)):\n",
        "          encoded_notes.append(self.pitch2int[self.notes[i]])\n",
        "      self.encoded_notes = np.array(encoded_notes)\n",
        "      \n",
        "  # save extracted notes as CSV for easy upload/access\n",
        "  def save_notes(self):\n",
        "    df = pd.DataFrame(self.notes)\n",
        "    df.to_csv(\"notes.csv\", header=None, index=None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jV8CId18C418",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below are functions we will use during training:\n",
        "\n",
        "\n",
        "*   `to_categorical` : one-hot encodes a batch \n",
        "*   `get_batches` : creates a batch of notes to be fed to the network (currently predicting 3 notes at a time)\n",
        "*   `save_model` : saves the model during training\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "k_iNnCZqUvTM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# helper functions \n",
        "\n",
        "def to_categorical(x, num_classes):\n",
        "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
        "    return np.eye(num_classes, dtype=np.float32)[x]\n",
        "  \n",
        "\n",
        "def get_batches(arr, batch_size, seq_length):  \n",
        "  \n",
        "  '''          \n",
        "  Generator which creates batches of dim (batch_size * seq_length)\n",
        "  batch_size = num sequences in a batch\n",
        "  seq_length = num of notes in a sequence\n",
        "  '''\n",
        "  batch_size_total = batch_size * seq_length\n",
        "  # total number of batches we can make\n",
        "  n_batches = len(arr)//batch_size_total\n",
        "\n",
        "  # keep only enough notes to make full batches\n",
        "  arr = arr[:n_batches * batch_size_total]\n",
        "  # reshape so we have as many rows/sequences as batch_size\n",
        "  arr = arr.reshape((batch_size, -1))\n",
        "\n",
        "  # iterate through the arr (cols), one sequence at a time\n",
        "  for n in range(0, arr.shape[1], seq_length):\n",
        "      # features\n",
        "      x = arr[:, n:n+seq_length]\n",
        "      # targets\n",
        "      y = np.zeros_like(x)\n",
        "      try:\n",
        "          # targets are shifted by one for single note pred\n",
        "          # try: y =-3 for multiple, x=2\n",
        "          y[:, :-2], y[:, -2] = x[:, 2:], arr[:, n+seq_length-3]\n",
        "      except IndexError:\n",
        "          # grab last target values for single note pred\n",
        "          # try: -3 for multiple, x=2\n",
        "          y[:, :-2], y[:, -2] = x[:, 2:], arr[:, 3]\n",
        "      yield x, y\n",
        "\n",
        "# save the model\n",
        "def save_model(best=False):\n",
        "  if best:\n",
        "    model_name = 'best_noteRNN.net'\n",
        "    print(\"Saving Best Perf Model....\")\n",
        "  else:\n",
        "    model_name = 'noteRNN.net'\n",
        "\n",
        "  checkpoint = {'state_dict': net.state_dict(),\n",
        "                'input_size': net.num_classes,\n",
        "                'output_size': net.num_classes,\n",
        "                'criterion_state': criterion.state_dict(),\n",
        "                'optimizer_state': optimizer.state_dict(),\n",
        "                'epochs': num_epochs}\n",
        "  try:\n",
        "    torch.save(checkpoint, model_name)\n",
        "  except:\n",
        "    print(\"Unable to save..\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q07z82VFD7MX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The class NoteRNN is an LSTM initialized with:\n",
        "\n",
        "\n",
        "*   `dropout` : specify percent for dropout - 0.3 (30%) is the default\n",
        "*   `num_layers`: number of hidden layers - 1 is the default\n",
        "*  `num_hidden`: number of hidden units - 256 is the default\n",
        "*  `lr`: learning rate - 0.003 is the default\n",
        "*  `num_classes`: equal to the number of `unique_notes` in our dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "zI_rt8K7Uv7E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NoteRNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, unique_notes, num_hidden=256, num_layers=3,\n",
        "                               dropout=0.3, lr=0.003):\n",
        "        super().__init__()\n",
        "        self.dropout = dropout\n",
        "        self.num_layers = num_layers\n",
        "        self.num_hidden = num_hidden\n",
        "        self.lr = lr\n",
        "        self.num_classes = len(unique_notes)\n",
        "            \n",
        "        # note dictionaries\n",
        "        self.note2int = dict((note, number) for number, note in enumerate(unique_notes))\n",
        "        self.int2note = dict(enumerate(self.note2int))\n",
        "        \n",
        "        # define LSTM\n",
        "        self.lstm = nn.LSTM(self.num_classes, num_hidden, num_layers, \n",
        "                            dropout=dropout, batch_first=True)\n",
        "        \n",
        "        # define dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        # define (fully connected) output layer\n",
        "        self.fc = nn.Linear(num_hidden, self.num_classes)\n",
        "      \n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        ''' Forward pass through the network. \n",
        "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
        "                \n",
        "        # get outputs and new hidden state from LSTM\n",
        "        r_output, hidden = self.lstm(x, hidden)\n",
        "        \n",
        "        # dropout layer\n",
        "        out = self.dropout(r_output)\n",
        "        \n",
        "        # Stack up LSTM outputs using view\n",
        "        # for multiple, use contiguous to reshape the output\n",
        "        out = out.contiguous().view(-1, self.num_hidden)\n",
        "        \n",
        "        # fully-connected layer\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        # return final output and hidden state\n",
        "        return out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # create 2 tensors of dim: (n_layers x batch_size x n_hidden)\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.num_layers, batch_size, self.num_hidden).zero_().cuda(),\n",
        "                  weight.new(self.num_layers, batch_size, self.num_hidden).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.num_layers, batch_size, self.num_hidden).zero_(),\n",
        "                      weight.new(self.num_layers, batch_size, self.num_hidden).zero_())\n",
        "        \n",
        "        return hidden\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1LELa15hKtJ-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The function `train` takes in an network - `net`, the `data` (our list of notes), trains the network for the specified number of `epochs`, saves each epoch, as well as the best performing (lowest valid) epoch. We split the data into train and valid sets, with a split size based on the parameter `val_split` fraction.  `batch_size,` `seq_length` and `lr` should all be set, though defaults are provided."
      ]
    },
    {
      "metadata": {
        "id": "yXjBRxCQUxpd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(net, data, epochs=100, batch_size=10, seq_length=60, lr=0.001, clip=5, val_split=0.1, print_every=20):\n",
        "    '''          \n",
        "        net: a NoteRNN network\n",
        "        data: encoded notes from which to train the network\n",
        "        epochs: num of epochs to train\n",
        "        batch_size: batch size\n",
        "        seq_length: num of notes per batch\n",
        "        lr: learning rate\n",
        "        clip: gradient clipping\n",
        "        val_split: amount of data to reserve for validation split\n",
        "        print_every: num of steps for printing training and validation loss\n",
        "    \n",
        "    '''\n",
        "        \n",
        "\n",
        "    net.train()\n",
        "\n",
        "\n",
        "    # create training and val set\n",
        "    split = int(len(data)*(1-val_split))\n",
        "    data, val_data = data[:split], data[split:]\n",
        "    if(train_on_gpu):\n",
        "        net.cuda()\n",
        "    \n",
        "    counter = 0\n",
        "    num_notes = net.num_classes\n",
        "    val_loss_min = np.Inf # track change in validation loss\n",
        "    for epoch in range(epochs):\n",
        "        # initialize hidden state\n",
        "        h = net.init_hidden(batch_size)\n",
        "        \n",
        "        for x, y in get_batches(data, batch_size, seq_length):\n",
        "            counter += 1\n",
        "            \n",
        "            # One-hot encode\n",
        "            x = to_categorical(x, num_notes)\n",
        "            # make torch tensors\n",
        "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
        "            # switch to gpu\n",
        "            if(train_on_gpu):\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "            # Creating new variables for the hidden state, otherwise\n",
        "            # we'd backprop through the entire training history\n",
        "            h = tuple([each.data for each in h])\n",
        "\n",
        "            # zero out gradient\n",
        "            net.zero_grad()\n",
        "            \n",
        "            # get output from net\n",
        "            output, h = net(inputs, h)\n",
        "            \n",
        "            # calculate the loss\n",
        "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
        "            # backprop\n",
        "            loss.backward()\n",
        "            \n",
        "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "            \n",
        "            # update weights and biases\n",
        "            optimizer.step()\n",
        "                        \n",
        "            # loss stats\n",
        "            if counter % print_every == 0:\n",
        "                print(\"Calculating loss...\")\n",
        "                # Get validation loss\n",
        "                val_h = net.init_hidden(batch_size)\n",
        "                val_losses = []\n",
        "                # turn dropout off\n",
        "                net.eval()\n",
        "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
        "                    # One-hot encode \n",
        "                    x = to_categorical(x, num_notes)\n",
        "                    # make Torch tensors\n",
        "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
        "                    \n",
        "                    # Creating new variables for the hidden state, otherwise\n",
        "                    # we'd backprop through the entire training history\n",
        "                    val_h = tuple([each.data for each in val_h])\n",
        "                    \n",
        "                    inputs, targets = x, y\n",
        "                    # move targets/inputs to gpu\n",
        "                    if(train_on_gpu):\n",
        "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "                    # get output from net \n",
        "                    output, val_h = net(inputs, val_h)\n",
        "                    # calc loss\n",
        "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
        "                    val_losses.append(val_loss.item())\n",
        "                # turn dropout back on for training\n",
        "                net.train()\n",
        "                \n",
        "                print(\"Epoch: {}/{}...\".format(epoch+1, epochs),\n",
        "                      \"Step: {}...\".format(counter),\n",
        "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
        "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
        "                \n",
        "                # save model if validation loss has decreased\n",
        "                if val_loss.item() <= val_loss_min:\n",
        "                    print('Saving best performing model...')\n",
        "                    save_model(best=True)\n",
        "                    val_loss_min = val_loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "__tsKbx-MY_Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Specify the data directory for the music files:"
      ]
    },
    {
      "metadata": {
        "id": "5e4p5Fy-UqTU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# directory where we store our music data\n",
        "data_dir = '/content/drive/My Drive/Colab Notebooks/data/music_data/music/classical_/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K8kN-zNzMdlw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create the `Dataset`, print the `.num_classes`, and retrieve the `encoded_notes` to be passed into the network."
      ]
    },
    {
      "metadata": {
        "id": "ESAaYZmnQHOa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create dataset\n",
        "classical = Dataset(data_dir)\n",
        "classical.create_dataset()\n",
        "print(\"Vocab size: {}\".format(classical.num_classes))\n",
        "encoded_notes = classical.encoded_notes # encode notes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QmMoXPG_Mr2_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we define the network:"
      ]
    },
    {
      "metadata": {
        "id": "GQ04O1YoU2EQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define and print the network\n",
        "num_hidden=500\n",
        "num_layers=1\n",
        "\n",
        "net = NoteRNN(classical.unique_notes, num_hidden, num_layers)\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-0SlVcAZMzN3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Specify the training parameters, `optimizer` and `criterion`"
      ]
    },
    {
      "metadata": {
        "id": "YtB04JbhU3U_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "batch_size = 10 # increase with larger dataset\n",
        "seq_length = 100# seq length really matters- it's the amount of context the net receives!\n",
        "num_epochs = 5\n",
        "# optimizer and criterion\n",
        "lr =0.001\n",
        "optimizer = torch.optim.SGD(net.parameters(),lr = lr, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3KLVXfevM4FP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Let's train!"
      ]
    },
    {
      "metadata": {
        "id": "8jEFCYeuU6Zp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "train(net, encoded_notes, epochs=num_epochs, batch_size=batch_size, seq_length=seq_length, lr=lr, print_every=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cCmzJ21OM6C-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The function `predict_multi` takes in a trained network, `net`, and return the hidden state and the next 3 predicted notes"
      ]
    },
    {
      "metadata": {
        "id": "ahm0lFmiU8Nc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# predict_multi takes in a trained network and returns\n",
        "# hidden state and the predicted next 3 notes\n",
        "def predict_multi(net, notes, h=None, top_k=None):\n",
        "\n",
        "        x = []\n",
        "    # extract notes\n",
        "        for nt in notes:\n",
        "          if nt in net.note2int:\n",
        "            # encode note\n",
        "            x.append(net.note2int[nt])\n",
        "          else:\n",
        "            # add note to note2int dict\n",
        "            net.note2int[nt.fullName] = len(net.note2int)+1\n",
        "            x.append(net.note2int[nt])\n",
        "        # create np array to one-hot encode\n",
        "        x = np.array(x)  \n",
        "        x = x.reshape((1, -1)) # reshape to (1,3)\n",
        "        # one-hot encode\n",
        "        x = to_categorical(x, len(net.note2int))\n",
        "        # create torch tensor\n",
        "        inputs = torch.from_numpy(x)\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs = inputs.cuda()\n",
        "        \n",
        "        # detach hidden state from history\n",
        "        h = tuple([each.data for each in h])\n",
        "        \n",
        "        # get the output of the model\n",
        "        out, h = net(inputs, h)\n",
        "\n",
        "        # get the character probabilities\n",
        "        probs = F.softmax(out, dim=1).data\n",
        "        if(train_on_gpu):\n",
        "            probs = probs.cpu() # move to cpu\n",
        "        \n",
        "        # get top predicted notes\n",
        "        if top_k is None:\n",
        "            top_ch = np.arange(net.num_classes)\n",
        "        else:\n",
        "            preds = []\n",
        "            top_choices = []\n",
        "            # for each class probability\n",
        "            for p in probs:\n",
        "              # get the top k values\n",
        "              pred, top_ch = p.topk(top_k)\n",
        "              # add the predictions for the notes\n",
        "              preds.append(pred.numpy().squeeze())\n",
        "              top_choices.append(top_ch.numpy().squeeze())\n",
        "       \n",
        "        # select the likely next note with some element of randomness\n",
        "        pred = []\n",
        "        for i in range(len(preds)):\n",
        "          # get the top 3 choices from each pred\n",
        "          nts = np.random.choice(top_choices[i], 3)\n",
        "          # convert int encoded note back to note\n",
        "          pred.append([net.int2note[nt] for nt in nts])\n",
        "      \n",
        "        # return the encoded value of the predicted note and the hidden state\n",
        "        return pred, h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "szW6yx0-NCIq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The function `sample`, generates a sample of notes given a trained network, `size` of the sample to be generated, and list of notes which act as the seed, or` prime`"
      ]
    },
    {
      "metadata": {
        "id": "SvJFsb_8U_Hx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# generate a sample of notes given a list of notes (prime)\n",
        "def sample(net, size, prime=['C'], top_k=None):\n",
        "        \n",
        "    if(train_on_gpu):\n",
        "        net.cuda()\n",
        "    else:\n",
        "        net.cpu()\n",
        "    # eval mode (don't want dropout on)\n",
        "    net.eval() \n",
        "    \n",
        "    # retrieve all notes from prime\n",
        "    notes = [nt for nt in prime]\n",
        "    h = net.init_hidden(1)\n",
        "    for nt in notes:        \n",
        "      # predict next 3 notes for each note or note sequence in prime\n",
        "      pred_notes, h = predict_multi(net, nt, h, top_k=top_k)\n",
        "    # for each sequence of predicted notes add it to the list of notes\n",
        "    for nt in pred_notes:\n",
        "      notes.append(nt)\n",
        "    \n",
        "    # use the output (last 3 predicted notes) to generate new prediction\n",
        "    for ii in range(size):\n",
        "      # continue predicting until we reach the desired number of generated notes (size)\n",
        "        pred_notes, h = predict_multi(net, notes[-3], h, top_k=top_k)\n",
        "        for nt in pred_notes: # add each prediction to the list of notes\n",
        "          notes.append(nt)\n",
        "    # flatten the list to be able to generate a midi file\n",
        "    flat_notes = []      \n",
        "    for nts in notes:\n",
        "      for nt in nts:\n",
        "        flat_notes.append(nt)\n",
        "\n",
        "    return flat_notes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IcxRPqj9NJ6H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The class Song takes in `generated_notes` from our sample function, the `note_dict` from our trained network, a `data_dir` specifying where we'd like to save the MIDI file, and a `file_name`."
      ]
    },
    {
      "metadata": {
        "id": "hPruM-3kbxLR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Song:\n",
        "  '''\n",
        "  generated_notes: list of notes (str) to be added to the midi file\n",
        "  note_dict: dict of music21 note objects from the trained network to convert our str notes to note objects\n",
        "  data_dir: directory to which we'll save the midi file\n",
        "  file_name: desired filename of the midi file\n",
        "  mt: to be Miditrack\n",
        "  d: duration (for midi events)\n",
        "  '''\n",
        "  def __init__(self, generated_notes, note_dict, data_dir, file_name):\n",
        "    self.generated_notes = generated_notes\n",
        "    self.note_dict = note_dict\n",
        "    self.data_dir = data_dir\n",
        "    self.file_name = file_name\n",
        "    self.mt = None\n",
        "    self.d = 0\n",
        "\n",
        "  def create_rest(self, nt):\n",
        "    # split on the separator, retrieve the last rest\n",
        "    rest = nt.split('$')[-1] \n",
        "    # retrieve the duration of the rest\n",
        "    duration = self.note_dict[rest].duration.quarterLength\n",
        "    return int(duration)\n",
        "  \n",
        "          \n",
        "  # end midi track\n",
        "  def end_track(self):\n",
        "    # create delta time\n",
        "    dt = midi.DeltaTime(self.mt)\n",
        "    dt.time = 0 # end of track, dt=0\n",
        "    self.mt.events.append(dt)\n",
        "    # create end of track event\n",
        "    me = midi.MidiEvent(self.mt)\n",
        "    me.type = \"END_OF_TRACK\"\n",
        "    me.channel = 1 # specify channel\n",
        "    me.data =''  # must set data to empty string\n",
        "    self.mt.events.append(me)\n",
        "   \n",
        "          \n",
        "    # create a midi file using the generated notes\n",
        "  def create_song(self):\n",
        "    # initialize midi track\n",
        "    self.mt = midi.MidiTrack(1)\n",
        "    \n",
        "    # where to save the file\n",
        "    file_path = self.data_dir+self.file_name\n",
        "    \n",
        "    for nt in self.generated_notes:\n",
        "      \n",
        "      velocity = 0\n",
        "      pitch_ = 0\n",
        "      duration = 0\n",
        "      \n",
        "      # takes in a str and creates a music21 note object\n",
        "      if \"Note\" in nt:\n",
        "        note_ = self.note_dict[nt] # retrieve note object\n",
        "        self.d = int(note_.duration.quarterLength) # retrieve duration\n",
        "        # convert note to midi event\n",
        "        eventList = midi.translate.noteToMidiEvents(note_, includeDeltaTime=True)\n",
        "        for event in eventList:\n",
        "          self.mt.events.append(event) # add midi event to the midi track\n",
        "        \n",
        "      elif \"Rest\" in nt: \n",
        "        # create rests\n",
        "        self.d = self.create_rest(nt)\n",
        "        # create delta time events \n",
        "        dt1 = midi.DeltaTime(self.mt) \n",
        "        me1 = midi.MidiEvent(self.mt)\n",
        "        dt1.time = 0 # start time = 0\n",
        "        me1.type=\"DeltaTime\"\n",
        "        self.mt.events.append(dt1) # add dt event to mt\n",
        "        dt2 = midi.DeltaTime(self.mt)\n",
        "        me2 = midi.MidiEvent(self.mt)\n",
        "        dt2.time = self.d # duration of delta time event\n",
        "        me2.type=\"DeltaTime\"\n",
        "        self.mt.events.append(dt2) # add dt event to mt\n",
        "\n",
        "      else: \n",
        "        # get chord\n",
        "        c = self.note_dict[nt] # retrieve music21 chord object\n",
        "        self.d = int(c.duration.quarterLength) # retrieve duration\n",
        "        # create midi event\n",
        "        eventList = midi.translate.chordToMidiEvents(c, includeDeltaTime=True)\n",
        "        #add to midi track events\n",
        "        for event in eventList:\n",
        "          self.mt.events.append(event)\n",
        "\n",
        "                   \n",
        "    # create event to end track\n",
        "    self.end_track()\n",
        "     # update events so they are all on this track\n",
        "    self.mt.updateEvents()\n",
        "    # create midi file to write\n",
        "    mf = midi.MidiFile()\n",
        "    mf.ticksPerQuarterNote = 424 #1024 default experiment with different timing (higher=more notes)\n",
        "    mf.tracks.append(self.mt)\n",
        "    # write midi file\n",
        "    print(\"Writing MIDI track\")\n",
        "    mf.open(file_path, 'wb')\n",
        "    mf.write()\n",
        "    mf.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SJ1B4s2NPOQn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Let's generate some notes!"
      ]
    },
    {
      "metadata": {
        "id": "lDVueencU_u-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# generate notes\n",
        "generated_notes = sample(net, 5, prime=[['F-sharp in octave 4 Eighth Triplet (1/3 QL) Note',\n",
        " 'F-sharp in octave 3 16th Note',\n",
        "]], top_k = 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "si-ZbUQLPTCB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lastly, we'll create a `Song`, by passing in the `generated_notes`, `.music21_objects`created from our dataset, `data_dir` where we'll write the MIDI file to, and a `file_name`. Use the `create_song` method to actually create the song."
      ]
    },
    {
      "metadata": {
        "id": "KrIwvlpBVBLT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create song and save it\n",
        "song = Song(generated_notes, classical.music21_objects, data_dir, \"multinote_generated_classical_9.mid\")\n",
        "song.create_song()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ujdPfnWeK7Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}